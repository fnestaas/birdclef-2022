{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the split\n",
    "Notebook for testing SelectSplitData and prepare a new way for splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from modules.TransformApplier import TransformApplier\n",
    "from modules.Wav2Spec import Wav2Spec\n",
    "from modules.SimpleDataset import SimpleDataset\n",
    "from modules.PretrainedModel import *\n",
    "from modules.OnlyXTransform import OnlyXTransform\n",
    "from modules.SelectSplitData import *\n",
    "from modules.SimpleAttention import *\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import timm\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Define how the DataLoaders should batch the data\n",
    "    \"\"\"\n",
    "    max_dim = max([d[0].shape[-1] for d in data])\n",
    "    pad_x = lambda x: torch.concat([x, torch.zeros((max_dim - x.shape[-1], ))])\n",
    "    return torch.stack([pad_x(d[0]) for d in data], axis=0), torch.stack([torch.tensor(d[1]) for d in data])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "metadata = pd.read_csv(f'{DATA_PATH}train_metadata.csv')[:4000]\n",
    "\n",
    "with open(f'{DATA_PATH}all_birds.json') as f:\n",
    "    birds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = metadata.sample(frac=.05).index # train test split\n",
    "df_val = metadata.iloc[tts]\n",
    "df_train = metadata.drop(axis=0,index=tts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 13)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = SimpleDataset(df_train, DATA_PATH, mode='train', labels=birds)\n",
    "val_data = SimpleDataset(df_val, DATA_PATH, mode='train', labels=birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.5"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "train_loader = DataLoader(train_data, batch_size=bs, num_workers=0, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=bs, num_workers=0, collate_fn=collate_fn)\n",
    "# 1 row per batch: 47 rows for val, 882 for train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3876096\n",
      "8476212\n",
      "9706656\n",
      "4801515\n",
      "5250816\n",
      "5108297\n",
      "3375438\n",
      "3180669\n",
      "4635648\n",
      "2907648\n",
      "3778351\n",
      "22062393\n",
      "2644992\n"
     ]
    }
   ],
   "source": [
    "for x,y in val_loader:\n",
    "    print(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    " inputs, classes = next(iter(val_loader))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3876096])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v, y_v = data_pipeline_val((inputs.to(device),classes.to(device).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242.256"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape[-1]/16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605763 1085763\n",
      "480000\n"
     ]
    }
   ],
   "source": [
    "duration = 30\n",
    "n_splits = 5\n",
    "sr = 16000\n",
    "total_duration = inputs.shape[-1] / sr\n",
    "max_offset = total_duration - duration \n",
    "offset = uniform(low=0.0, high=max_offset)\n",
    "start = int(offset*sr)\n",
    "stop = min([int((offset + duration)*sr), inputs.shape[-1]])\n",
    "print(start,stop)\n",
    "print(stop - start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs[..., start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 480000])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 96000])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.reshape((inputs.shape[0]*n_splits, *inputs.shape[1:-1], -1)).shape\n",
    "# x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 96000])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "duration = 30\n",
    "n_splits = 5\n",
    "transforms1 = TransformApplier([nn.Identity(), SelectSplitData(duration, n_splits)])\n",
    "data_pipeline_val = nn.Sequential(transforms1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_v,y_v in val_loader:\n",
    "    x_v, y_v = data_pipeline_val((x_v.to(device),y_v.to(device)).float)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}