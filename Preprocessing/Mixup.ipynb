{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to implement mixup for the preprocessing, as in https://github.com/facebookresearch/mixup-cifar10/blob/main/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    #Returns mixed inputs, pairs of targets, and lambda\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mixup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m audio, label\n\u001b[0;32m     53\u001b[0m \u001b[39m#Something like:\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m mixup\n\u001b[0;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[0;32m     56\u001b[0m     data[i],targets\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mixup' is not defined"
     ]
    }
   ],
   "source": [
    "#Mixup, as implemented in https://towardsdatascience.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms Instead, import the audio transforms and use those, so we can use audiomentation and mixup\n",
    "#at the same time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Mixup(Dataset):\n",
    "    def __init__(self,data,transform,targets):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.nrow=len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.size(self.data)[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Create a one hot label\n",
    "        label = torch.zeros(21) #how many do we detect?\n",
    "        label[self.targets[idx]] = 1.\n",
    "\n",
    "        # Transform the image by converting to tensor and normalizing it\n",
    "        if self.transform:\n",
    "            audio = self.transform(self.data[idx])\n",
    "\n",
    "        #only perform mixup roughly on 1 for every 5 audios\n",
    "        if idx > 0 and idx%5 == 0:\n",
    "\n",
    "            # Choose another audio/label randomly\n",
    "            mixup_idx = random.randint(0, len(self.data)-1)\n",
    "            mixup_label = torch.zeros(21)\n",
    "            label[self.targets[mixup_idx]] = 1.\n",
    "            if self.transform:\n",
    "                mixup_audio = self.transform(self.data[mixup_idx])\n",
    "\n",
    "            # Select a random number from the given beta distribution\n",
    "            # Mixup the images accordingly\n",
    "            alpha = 0.2\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "            audio = lam * audio + (1 - lam) * mixup_audio\n",
    "            label = lam * label + (1 - lam) * mixup_label\n",
    "\n",
    "        return audio, label\n",
    "    \n",
    "#Something like:\n",
    "'''mixup_data=clone(data)\n",
    "mixup_labels=clone(labels)\n",
    "for i in range(len(data)):\n",
    "    mixup_data[i],mixup_targets[i]=Mixup(data,transform,targets)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfcdafd4c2f198e9231774dbaa691ef2a9d56c92dabac0fe3d9f172dfc08608e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
